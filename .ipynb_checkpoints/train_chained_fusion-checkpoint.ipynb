{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bhandawatlab_duke/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "# tfe.enable_eager_execution()\n",
    "import sys\n",
    "sys.path.append(r'~/Pose Estimation Keras')\n",
    "import cnn\n",
    "from cnn import conv_base\n",
    "from build_dataset import Dataset\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import normalize\n",
    "from scipy import stats\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from time import time\n",
    "import cv2\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 30)        552990    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 28, 28, 24)        6504      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 56, 56, 18)        3906      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 112, 112, 12)      1956      \n",
      "_________________________________________________________________\n",
      "same (Conv2DTranspose)       (None, 224, 224, 6)       654       \n",
      "_________________________________________________________________\n",
      "deconvolution_fusion_network (None, 224, 224, 1)       55        \n",
      "_________________________________________________________________\n",
      "deconvolution_network_output (None, 224, 224, 6)       60        \n",
      "=================================================================\n",
      "Total params: 24,153,837\n",
      "Trainable params: 24,100,717\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "total_frames = 5\n",
    "frame_height = 224\n",
    "frame_width = 224\n",
    "frame_channels = 3\n",
    "num_bodyparts = 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_deconv_model():\n",
    "    frame_tensor = conv_base.layers[0].get_input_at(0)\n",
    "    resnet_output = cnn.convolution_network(frame_tensor)\n",
    "    model_resnet = models.Model(inputs=[frame_tensor], outputs=[resnet_output])\n",
    "    \n",
    "    deconv_output = cnn.deconvolution_fusion_network(model_resnet.output)\n",
    "    deconv_separate_output = cnn.separation_network(deconv_output)\n",
    "    model_deconv = models.Model(inputs=[frame_tensor], outputs=[deconv_output , deconv_separate_output])\n",
    "    \n",
    "    losses = {\"deconvolution_network_output\": \"binary_crossentropy\",\n",
    "        \"deconvolution_fusion_network_output\": \"binary_crossentropy\",\n",
    "        \n",
    "#         \"spatial_fusion_output\": \"binary_crossentropy\",\n",
    "#         \"optical_flow_output\": \"binary_crossentropy\"\n",
    "    }\n",
    "    lossWeights = {\"deconvolution_fusion_network_output\": 1.0,\n",
    "                  \"deconvolution_network_output\": 1.0}\n",
    "#                    \"spatial_fusion_output\": 1.0,\n",
    "#                    \"optical_flow_output\": 1.0}\n",
    "    \n",
    "#     opt = optimizers.SGD(lr = 0.0, momentum=0.9, nesterov=True)\n",
    "    opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    model_deconv.compile( optimizer=opt, loss=losses, loss_weights=lossWeights, metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model_deconv\n",
    "\n",
    "model = build_deconv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 6, 7, 8, 11, 15, 16, 17, 18, 19, 20, 23, 120, 126, 127, 178, 185, 199, 228, 244, 261, 267, 285, 306, 335, 367, 375, 389, 405, 410, 415, 420, 426, 430, 436, 440, 445, 452, 455, 460, 465, 470, 476, 480, 485, 490, 496, 500, 511, 520, 525, 530, 535, 542, 552, 555, 568, 570, 575, 581, 588, 595, 600, 605, 610, 615, 621, 625, 633, 636, 640, 645, 650, 655, 665, 670, 675, 680, 685, 690, 695, 700, 705, 710, 715, 718, 723, 725, 751, 755, 770, 783, 784, 804, 812, 816, 823, 829, 838, 841, 845, 850, 855, 863, 865, 891, 894, 904, 908, 915, 920, 929, 946, 953, 955, 959, 965, 970, 980, 987, 990, 995, 1030, 1035, 1041, 1045, 1160, 1164, 1170, 1174, 1220, 1225, 1230, 1235, 1240, 1245, 1250, 1255, 1267, 1275, 1280, 1285, 1290]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def parse_csv(file):\n",
    "    with open(file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        indices = []\n",
    "        for line in csv_reader:\n",
    "            indices.extend([int(f) for f in line if f!=''])\n",
    "    return indices\n",
    "\n",
    "indices = parse_csv('dataset_indices.csv')\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 5, 224, 224, 6)\n",
      "(146, 5, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('../dataset.h5', 'r') as hf:\n",
    "#     central_heatmap = hf['central_heatmap'][indices]\n",
    "    frames = hf['frames'][indices]\n",
    "    heatmaps_individual = hf['heatmaps_individual'][indices]\n",
    "    heatmaps_combined = hf['heatmaps_combined'][indices]\n",
    "    \n",
    "home_dir = os.getcwd()\n",
    "# central_heatmap = np.expand_dims(central_heatmap, axis=-1)\n",
    "heatmaps_combined = np.expand_dims(heatmaps_combined, axis=-1)\n",
    "heatmaps_individual = np.swapaxes(heatmaps_individual, 2, 4)\n",
    "# print(central_heatmap.shape)\n",
    "print(heatmaps_individual.shape)\n",
    "print(heatmaps_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    try:\n",
    "        if epoch < 30:\n",
    "            lrate = 0.0001\n",
    "        elif epoch < 70:\n",
    "            lrate = 0.00005\n",
    "        elif epoch < 200:\n",
    "            lrate = 0.00001\n",
    "        return lrate\n",
    "    except:\n",
    "        print('Error in setting learning rate')\n",
    "lrate = LearningRateScheduler(step_decay, verbose=1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath= os.path.join(home_dir, \"pretrained_models/model_chained_fusion_11419.h5\"),\n",
    "                               verbose=1,\n",
    "                               monitor='loss')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(home_dir, \"logs/{}\".format(time())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
